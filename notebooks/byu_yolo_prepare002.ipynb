{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11e5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\n",
    "import cv2\n",
    "import threading\n",
    "import time\n",
    "from contextlib import nullcontext\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66cafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting\n",
    "DEBUG_MODE = False\n",
    "PATCH_SIZE = 640\n",
    "TRUST = 5\n",
    "BOX_SIZE = 30\n",
    "TRAIN_SPLIT = 0.8\n",
    "CONCENTRATION = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a620a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_slice(slice_data):\n",
    "    \"\"\"\n",
    "    Normalize slice data using the 2nd and 98th percentiles.\n",
    "    \n",
    "    Args:\n",
    "        slice_data (numpy.array): Input image slice.\n",
    "    \n",
    "    Returns:\n",
    "        np.uint8: Normalized image in the range [0, 255].\n",
    "    \"\"\"\n",
    "    p2 = np.percentile(slice_data, 2)\n",
    "    p98 = np.percentile(slice_data, 98)\n",
    "    clipped_data = np.clip(slice_data, p2, p98)\n",
    "    normalized = 255 * (clipped_data - p2) / (p98 - p2)\n",
    "    return np.uint8(normalized)\n",
    "\n",
    "# Define the preprocessing function to extract slices, normalize, and generate YOLO annotations.\n",
    "def prepare_yolo_dataset(trust=TRUST, train_split=TRAIN_SPLIT, dir_info=None):\n",
    "    \"\"\"\n",
    "    Extract slices containing motors and save images with corresponding YOLO annotations.\n",
    "    \n",
    "    Steps:\n",
    "    - Load the motor labels.\n",
    "    - Perform a train/validation split by tomogram.\n",
    "    - For each motor, extract slices in a range (Â± trust parameter).\n",
    "    - Normalize each slice and save it.\n",
    "    - Generate YOLO format bounding box annotations with a fixed box size.\n",
    "    - Create a YAML configuration file for YOLO training.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A summary containing dataset statistics and file paths.\n",
    "    \"\"\"\n",
    "    # Load the labels CSV\n",
    "    labels_df = pd.read_csv(os.path.join(dir_info['data_path'], \"train_labels.csv\"))\n",
    "    \n",
    "    total_motors = labels_df['Number of motors'].sum()\n",
    "    print(f\"Total number of motors in the dataset: {total_motors}\")\n",
    "    \n",
    "    # Consider only tomograms with at least one motor\n",
    "    tomo_df = labels_df[labels_df['Number of motors'] > 0].copy()\n",
    "    unique_tomos = tomo_df['tomo_id'].unique()\n",
    "    print(f\"Found {len(unique_tomos)} unique tomograms with motors\")\n",
    "    \n",
    "    # Shuffle and split tomograms into train and validation sets\n",
    "    np.random.shuffle(unique_tomos)\n",
    "    split_idx = int(len(unique_tomos) * train_split)\n",
    "    train_tomos = unique_tomos[:split_idx]\n",
    "    val_tomos = unique_tomos[split_idx:]\n",
    "    print(f\"Split: {len(train_tomos)} tomograms for training, {len(val_tomos)} tomograms for validation\")\n",
    "    \n",
    "    # Helper function to process a list of tomograms\n",
    "    def process_tomogram_set(tomogram_ids, images_dir, labels_dir, set_name):\n",
    "        motor_counts = []\n",
    "        for tomo_id in tomogram_ids:\n",
    "            # Get motor annotations for the current tomogram\n",
    "            tomo_motors = labels_df[labels_df['tomo_id'] == tomo_id]\n",
    "            for _, motor in tomo_motors.iterrows():\n",
    "                if pd.isna(motor['Motor axis 0']):\n",
    "                    continue\n",
    "                motor_counts.append(\n",
    "                    (tomo_id, \n",
    "                     int(motor['Motor axis 0']), \n",
    "                     int(motor['Motor axis 1']), \n",
    "                     int(motor['Motor axis 2']),\n",
    "                     int(motor['Array shape (axis 0)']))\n",
    "                )\n",
    "        \n",
    "        print(f\"Will process approximately {len(motor_counts) * (2 * trust + 1)} slices for {set_name}\")\n",
    "        processed_slices = 0\n",
    "        \n",
    "        # Loop over each motor annotation\n",
    "        for tomo_id, z_center, y_center, x_center, z_max in tqdm(motor_counts, desc=f\"Processing {set_name} motors\"):\n",
    "            z_min = max(0, z_center - trust)\n",
    "            z_max_bound = min(z_max - 1, z_center + trust)\n",
    "            for z in range(z_min, z_max_bound + 1):\n",
    "                if z % 3 == 0:\n",
    "                    continue\n",
    "                # Create the slice filename and source path\n",
    "                slice_filename = f\"slice_{z:04d}.jpg\"\n",
    "                src_path = os.path.join(dir_info['train_dir'], tomo_id, slice_filename)\n",
    "                if not os.path.exists(src_path):\n",
    "                    print(f\"Warning: {src_path} does not exist, skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Load, normalize, and save the image slice\n",
    "                img = Image.open(src_path)\n",
    "                img_array = np.array(img)\n",
    "                normalized_img = normalize_slice(img_array)\n",
    "                dest_filename = f\"{tomo_id}_z{z:04d}_y{y_center:04d}_x{x_center:04d}.jpg\"\n",
    "                dest_path = os.path.join(images_dir, dest_filename)\n",
    "                Image.fromarray(normalized_img).save(dest_path)\n",
    "                \n",
    "                # Prepare YOLO bounding box annotation (normalized values)\n",
    "                img_width, img_height = img.size\n",
    "                x_center_norm = x_center / img_width\n",
    "                y_center_norm = y_center / img_height\n",
    "                box_width_norm = BOX_SIZE / img_width\n",
    "                box_height_norm = BOX_SIZE / img_height\n",
    "                label_path = os.path.join(labels_dir, dest_filename.replace('.jpg', '.txt'))\n",
    "                with open(label_path, 'w') as f:\n",
    "                    f.write(f\"0 {x_center_norm} {y_center_norm} {box_width_norm} {box_height_norm}\\n\")\n",
    "                \n",
    "                processed_slices += 1\n",
    "        \n",
    "        return processed_slices, len(motor_counts)\n",
    "    \n",
    "    # Process training tomograms\n",
    "    train_slices, train_motors = process_tomogram_set(train_tomos, dir_info['yolo_images_train'], dir_info['yolo_labels_train'], \"training\")\n",
    "    # Process validation tomograms\n",
    "    val_slices, val_motors = process_tomogram_set(val_tomos, dir_info['yolo_images_val'], dir_info['yolo_labels_val'], \"validation\")\n",
    "    \n",
    "    # Generate YAML configuration for YOLO training\n",
    "    yaml_content = {\n",
    "        'path': dir_info['yolo_dataset_dir'],\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'names': {0: 'motor'}\n",
    "    }\n",
    "    with open(os.path.join(dir_info['yolo_dataset_dir'], 'dataset.yaml'), 'w') as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(f\"- Train set: {len(train_tomos)} tomograms, {train_motors} motors, {train_slices} slices\")\n",
    "    print(f\"- Validation set: {len(val_tomos)} tomograms, {val_motors} motors, {val_slices} slices\")\n",
    "    print(f\"- Total: {len(train_tomos) + len(val_tomos)} tomograms, {train_motors + val_motors} motors, {train_slices + val_slices} slices\")\n",
    "    \n",
    "    return {\n",
    "        \"dataset_dir\": dir_info['yolo_dataset_dir'],\n",
    "        \"yaml_path\": os.path.join(dir_info['yolo_dataset_dir'], 'dataset.yaml'),\n",
    "        \"train_tomograms\": len(train_tomos),\n",
    "        \"val_tomograms\": len(val_tomos),\n",
    "        \"train_motors\": train_motors,\n",
    "        \"val_motors\": val_motors,\n",
    "        \"train_slices\": train_slices,\n",
    "        \"val_slices\": val_slices\n",
    "    }\n",
    "\n",
    "def add_noize(image, label, noize_level=0.05):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to an image.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.array): Input image.\n",
    "        noize_level (float): Standard deviation of the Gaussian noise.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: Noisy image.\n",
    "    \"\"\"\n",
    "    # Validation data\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Image must be a numpy array.\")\n",
    "    if image.ndim != 3:\n",
    "        raise ValueError(\"Image must be a 3D array (height, width, channels).\")\n",
    "    if image.shape[2] != 3:\n",
    "        raise ValueError(\"Image must have 3 channels (RGB).\")\n",
    "    if not isinstance(label, list):\n",
    "        raise ValueError(\"Label must be a list.\")\n",
    "    noise = np.random.normal(0, noize_level * 255, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return noisy_image, label\n",
    "\n",
    "def add_blur(image, label, blur_level=5):\n",
    "    \"\"\"\n",
    "    Add Gaussian blur to an image.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.array): Input image.\n",
    "        blur_level (int): Size of the Gaussian kernel.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: Blurred image.\n",
    "    \"\"\"\n",
    "    # Validation data\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Image must be a numpy array.\")\n",
    "    if image.ndim != 3:\n",
    "        raise ValueError(\"Image must be a 3D array (height, width, channels).\")\n",
    "    if image.shape[2] != 3:\n",
    "        raise ValueError(\"Image must have 3 channels (RGB).\")\n",
    "    if not isinstance(label, list):\n",
    "        raise ValueError(\"Label must be a list.\")\n",
    "    if blur_level % 2 == 0:\n",
    "        blur_level += 1\n",
    "    blurred_image = cv2.GaussianBlur(image, (blur_level, blur_level), 0)\n",
    "    return blurred_image, label\n",
    "\n",
    "def add_contrast(image, label, contrast_level=1.5):\n",
    "    \"\"\"\n",
    "    Adjust the contrast of an image.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.array): Input image.\n",
    "        contrast_level (float): Contrast adjustment factor.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: Contrast-adjusted image.\n",
    "    \"\"\"\n",
    "    # Validation data\n",
    "    if not isinstance(image, np.ndarray):\n",
    "        raise ValueError(\"Image must be a numpy array.\")\n",
    "    if image.shape[2] != 3:\n",
    "        raise ValueError(\"Image must have 3 channels (RGB).\")\n",
    "    if not isinstance(label, list):\n",
    "        raise ValueError(\"Label must be a list.\")\n",
    "    # Validation for contrast level\n",
    "    if contrast_level < 0:\n",
    "        raise ValueError(\"Contrast level must be non-negative.\")\n",
    "    if contrast_level == 0:\n",
    "        return image, label\n",
    "    \n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = np.clip(contrast_level * l, 0, 255).astype(np.uint8)\n",
    "    lab = cv2.merge((l, a, b))\n",
    "    contrast_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    return contrast_image, label\n",
    "\n",
    "def add_brightness(image, label, brightness_level=50):\n",
    "    \"\"\"\n",
    "    Adjust the brightness of an image.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.array): Input image.\n",
    "        brightness_level (int): Brightness adjustment value.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: Brightness-adjusted image.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    v = np.clip(v + brightness_level, 0, 255).astype(np.uint8)\n",
    "    hsv = cv2.merge((h, s, v))\n",
    "    brightness_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return brightness_image, label\n",
    "\n",
    "def add_flip(image, label):\n",
    "    \"\"\"\n",
    "    Flip an image horizontally.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy.array): Input image.\n",
    "        label (list): List of labels.\n",
    "            line: [x_center, y_center, width, height]\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: Flipped image.\n",
    "    \"\"\"\n",
    "    flipped_image = cv2.flip(image, 0)\n",
    "    if label is None:\n",
    "        return flipped_image, label\n",
    "    if len(label) == 0:\n",
    "        return flipped_image, label\n",
    "\n",
    "    for i, line in enumerate(label):\n",
    "        if len(line) != 5:\n",
    "            raise ValueError(f\"Invalid label format: {line}. Expected 5 values.\")\n",
    "        _, _, y_center, _, _ = line\n",
    "        y_center = 1 - y_center\n",
    "        line[2] = y_center\n",
    "        label[i] = line\n",
    "    return flipped_image, label\n",
    "\n",
    "def apply_augmentation(augmentations:dict, dir_info=None):\n",
    "    \"\"\"\n",
    "    Apply a series of augmentations to an image.\n",
    "    \n",
    "    Args:\n",
    "        augmentations (dict): List of augmentation functions to apply.\n",
    "        dir_info (dict): Directory information for saving images and labels.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: Augmented image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def _process_tomogram_set(_tomo_paths, _label_paths, images_dir, labels_dir, aug, _aug_name): #TODO: add augmentations\n",
    "        \"\"\"\n",
    "        Process a set of tomograms and apply augmentations.\n",
    "        \"\"\"\n",
    "\n",
    "        assert os.path.exists(images_dir), f\"Images directory {images_dir} does not exist.\"\n",
    "        assert os.path.exists(labels_dir), f\"Labels directory {labels_dir} does not exist.\"\n",
    "        assert len(_tomo_paths) == len(_label_paths), f\"Number of tomograms and labels do not match.\"\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        # Placeholder for processing logic\n",
    "        for tomo_path, label_path in tqdm(zip(_tomo_paths, _label_paths), desc=f\"Processing {_aug_name} tomograms\"):\n",
    "            # Load the image and labels\n",
    "            if not os.path.exists(label_path):\n",
    "                print(f\"Warning: {label_path} does not exist, skipping.\")\n",
    "                continue\n",
    "            if not os.path.exists(tomo_path):\n",
    "                print(f\"Warning: {tomo_path} does not exist, skipping.\")\n",
    "                continue\n",
    "            image = Image.open(tomo_path)\n",
    "            image = image.convert(\"RGB\")\n",
    "            image = np.array(image)\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = f.readlines()\n",
    "            # split the label into a list of lists\n",
    "            label = [list(map(float, line.split())) for line in label]\n",
    "            \n",
    "            _data_name = os.path.basename(tomo_path).replace('.jpg', '')\n",
    "            _data_name = f\"{_data_name}_{_aug_name}.jpg\"\n",
    "            image_dest_path = os.path.join(images_dir, _data_name)\n",
    "            label_path = os.path.join(labels_dir, _data_name.replace('.jpg', '.txt'))\n",
    "            label_dest_path = os.path.join(labels_dir, _data_name.replace('.jpg', '.txt'))\n",
    "            _data_name = _data_name + f\"_{_aug_name}\"\n",
    "            image, label = aug(image, label)\n",
    "            image = Image.fromarray(image)\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            image.save(image_dest_path)\n",
    "            images.append(image)\n",
    "            # Save the label\n",
    "            labels.append(label)\n",
    "            with open(label_dest_path, 'w') as f:\n",
    "                for line in label:\n",
    "                    line = f\"{int(line[0])} {line[1]} {line[2]} {line[3]} {line[4]}\"\n",
    "                    f.write(line + '\\n')\n",
    "        return images, labels\n",
    "\n",
    "    # Process training tomograms\n",
    "    train_tomos = os.listdir(dir_info['yolo_images_train'])\n",
    "    train_tomos = [item for item in train_tomos if not item.startswith('.')]\n",
    "    train_tomos = [os.path.join(dir_info['yolo_images_train'], item) for item in train_tomos]\n",
    "    train_labels = os.listdir(dir_info['yolo_labels_train'])\n",
    "    train_labels = [item for item in train_labels if not item.startswith('.')]\n",
    "    train_labels = [os.path.join(dir_info['yolo_labels_train'], item) for item in train_labels]\n",
    "    for aug_name, aug in augmentations.items():\n",
    "        train_slices, train_motors = _process_tomogram_set(train_tomos, train_labels,\n",
    "                                                           dir_info['yolo_images_train'],\n",
    "                                                           dir_info['yolo_labels_train'], aug, aug_name)\n",
    "    \n",
    "    # Process validation tomograms\n",
    "    val_tomos = os.listdir(dir_info['yolo_images_val'])\n",
    "    val_tomos = [item for item in val_tomos if not item.startswith('.')]\n",
    "    val_tomos = [os.path.join(dir_info['yolo_images_val'], item) for item in val_tomos]\n",
    "    val_labels = os.listdir(dir_info['yolo_labels_val'])\n",
    "    val_labels = [item for item in val_labels if not item.startswith('.')]\n",
    "    val_labels = [os.path.join(dir_info['yolo_labels_val'], item) for item in val_labels]\n",
    "    for aug_name, aug in augmentations.items():\n",
    "        val_slices, val_motors = _process_tomogram_set(val_tomos,val_labels,\n",
    "                                                       dir_info['yolo_images_val'],\n",
    "                                                       dir_info['yolo_labels_val'], aug, aug_name)\n",
    "    \n",
    "    # Generate YAML configuration for YOLO training\n",
    "    yaml_content = {\n",
    "        'path': dir_info['yolo_dataset_dir'],\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'names': {0: 'motor'}\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(dir_info['yolo_dataset_dir'], 'dataset.yaml'), 'w') as f:\n",
    "        yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "    \n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(f\"- Train set: {len(train_tomos)} tomograms, {len(train_motors)} motors, {len(train_slices)} slices\")\n",
    "    print(f\"- Validation set: {len(val_tomos)} tomograms, {len(val_motors)} motors, {len(val_slices)} slices\")\n",
    "    print(f\"- Total: {len(train_tomos) + len(val_tomos)} tomograms, {len(train_motors) + len(val_motors)} motors, {len(train_slices) + len(val_slices)} slices\")\n",
    "    \n",
    "    return {\n",
    "        \"dataset_dir\": dir_info['yolo_dataset_dir'],\n",
    "        \"yaml_path\": os.path.join(dir_info['yolo_dataset_dir'], 'dataset.yaml'),\n",
    "        \"train_tomograms\": len(train_tomos),\n",
    "        \"val_tomograms\": len(val_tomos),\n",
    "        \"train_motors\": train_motors,\n",
    "        \"val_motors\": val_motors,\n",
    "        \"train_slices\": train_slices,\n",
    "        \"val_slices\": val_slices\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2806e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of motors in the dataset: 831\n",
      "Found 362 unique tomograms with motors\n",
      "Split: 289 tomograms for training, 73 tomograms for validation\n",
      "Will process approximately 4004 slices for training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456148fc7ade46e29766230239aa6c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing training motors:   0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will process approximately 957 slices for validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc65cd7445b0422e8374606820e49d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing validation motors:   0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Summary:\n",
      "- Train set: 289 tomograms, 364 motors, 2664 slices\n",
      "- Validation set: 73 tomograms, 87 motors, 633 slices\n",
      "- Total: 362 tomograms, 451 motors, 3297 slices\n"
     ]
    }
   ],
   "source": [
    "yolo_dataset_dir = os.path.join(\"../input\",\"yolo_dataset\")\n",
    "os.makedirs(yolo_dataset_dir, exist_ok=True)\n",
    "yolo_images_train = os.path.join(yolo_dataset_dir, \"images/train\")\n",
    "yolo_images_val = os.path.join(yolo_dataset_dir, \"images/val\")\n",
    "yolo_labels_train = os.path.join(yolo_dataset_dir, \"labels/train\")\n",
    "yolo_labels_val = os.path.join(yolo_dataset_dir, \"labels/val\")\n",
    "os.makedirs(yolo_images_train, exist_ok=True)\n",
    "os.makedirs(yolo_images_val, exist_ok=True)\n",
    "os.makedirs(yolo_labels_train, exist_ok=True)\n",
    "os.makedirs(yolo_labels_val, exist_ok=True)\n",
    "\n",
    "dir_info = {\n",
    "    \"data_path\": \"../input/full_data\",\n",
    "    \"train_dir\": \"../input/full_data/train\",\n",
    "    # \"data_path\": \"../input/data\",\n",
    "    # \"train_dir\": \"../input/data/train\",\n",
    "    \"yolo_dataset_dir\": yolo_dataset_dir,\n",
    "    \"yolo_images_train\": yolo_images_train,\n",
    "    \"yolo_labels_train\": yolo_labels_train,\n",
    "    \"yolo_images_val\": yolo_images_val,\n",
    "    \"yolo_labels_val\": yolo_labels_val\n",
    "}\n",
    "\n",
    "# Prepare the YOLO dataset\n",
    "summary = prepare_yolo_dataset(trust=TRUST, train_split=TRAIN_SPLIT, dir_info=dir_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de7ebd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8784b80069f4051a77472a3e54ff63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing contrast tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7743d8ef7e604a14b5546f8cb61ab93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing brightness tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957d28a71edd4162aca1a3e19be04461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing blur tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a310c2faf442ceb193f2952c794bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing flip tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20007e79bf64700b155d80495811ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing noize tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4229be546044e5be2f1bd515bd62d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing contrast tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94aef57c5d9147cf8b20af4ad3ddbee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing brightness tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552e6a2293d148e7a86699d13317e991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing blur tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17148863fc54e639bc32964eadef964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing flip tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07485e6e7b504f72baffcc510c4fbd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing noize tomograms: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Summary:\n",
      "- Train set: 2596 tomograms, 2596 motors, 2596 slices\n",
      "- Validation set: 701 tomograms, 701 motors, 701 slices\n",
      "- Total: 3297 tomograms, 3297 motors, 3297 slices\n"
     ]
    }
   ],
   "source": [
    "augmentations = {\n",
    "    \"contrast\": add_contrast,\n",
    "    \"brightness\": add_brightness,\n",
    "    \"blur\": add_blur,\n",
    "    \"flip\": add_flip,\n",
    "    \"noize\": add_noize\n",
    "}\n",
    "\n",
    "summary = apply_augmentation(augmentations=augmentations, dir_info=dir_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
