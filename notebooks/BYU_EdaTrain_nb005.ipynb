{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1387fa7f",
   "metadata": {},
   "source": [
    "# Abstruct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d62fc35",
   "metadata": {},
   "source": [
    "# 0. Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Find session type\n",
    "def find_session_type():\n",
    "    # windows\n",
    "    if os.name == 'nt':\n",
    "        path = '../input/data/'\n",
    "\n",
    "        import japanize_matplotlib\n",
    "        sns.set(font=\"IPAexGothic\")\n",
    "\n",
    "    elif platform.system()  == 'Darwin':\n",
    "        # Mac\n",
    "        path = '../input/data/'\n",
    "        return 'mac'\n",
    "    \n",
    "    elif os.name == 'posix':\n",
    "    # Kaggle\n",
    "        if 'KAGGLE_DATA_PROXY_TOKEN' in os.environ.keys():\n",
    "            print('This is kaggle session')\n",
    "            return 'kaggle'\n",
    "\n",
    "    # Google Colab\n",
    "        else:\n",
    "            print('This is colab session')\n",
    "            # セッションの残り時間の確認\n",
    "            !cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 / 60 / 60 \"h)\"}'\n",
    "            return 'colab'\n",
    "    # Mac\n",
    "    # elif 'MAC' in os.environ.keys():\n",
    "    #     print('This is mac session')\n",
    "    #     return 'mac'\n",
    "# Example usage:\n",
    "if find_session_type() == 'kaggle':\n",
    "    print(\"Running in a Kaggle notebook\")\n",
    "elif find_session_type() == 'mac':\n",
    "    print(\"Running on a Mac\")\n",
    "    path = '../input/data/'\n",
    "\n",
    "elif find_session_type() == 'colab':\n",
    "    from google.colab import drive\n",
    "    print(\"Running in Google Colab\")\n",
    "    drive.mount('/content/drive')\n",
    "    os.makedirs('/content/logs', exist_ok=True)\n",
    "    os.makedirs('/content/kaggle/input', exist_ok=True)\n",
    "    os.makedirs('/content/kaggle/output', exist_ok=True)\n",
    "else:\n",
    "    print(\"Not running in a Kaggle notebook or Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86791f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        # General settings\n",
    "        self.debug = True\n",
    "        self.random_seed = 42\n",
    "        self.num_workers = 4\n",
    "        self.train_split = 0.8\n",
    "        self.model_name = \"yolov8n\"\n",
    "        self.batch_size = 2\n",
    "        random.seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        torch.manual_seed(self.random_seed)\n",
    "\n",
    "        cpu_count = os.cpu_count()\n",
    "        if find_session_type() == 'kaggle':\n",
    "            self.num_workers = min(4, cpu_count)  # Kaggle has limit\n",
    "        elif find_session_type() == 'colab':\n",
    "            self.num_workers = min(2, cpu_count)  # Colab is often limited\n",
    "        else:\n",
    "            self.num_workers = max(2, cpu_count // 2)  # Local: use half of CPUs\n",
    "\n",
    "        if find_session_type() == 'kaggle':\n",
    "            self.working_dir = '/kaggle/working/'\n",
    "            self.input_dir = '/kaggle/input/'\n",
    "            self.output_dir = '/kaggle/output/'\n",
    "        elif find_session_type() == 'colab':\n",
    "            self.working_dir = '/content/drive/MyDrive/kaggle/BYU-motor-detection/'\n",
    "            self.input_dir = '/content/kaggle/input/'\n",
    "            self.output_dir = '/content/kaggle/output/'\n",
    "        elif find_session_type() == 'mac':\n",
    "            self.working_dir = '/working'\n",
    "            self.input_dir = '/input/'\n",
    "            self.output_dir = '/output/'\n",
    "        \n",
    "        self.data_dir = os.path.join(self.input_dir, 'byu-locating-bacterial-flagellar-motors-2025')\n",
    "        \n",
    "        self.yolo_dataset_dir = os.path.join(self.working_dir, 'yolo_dataset')\n",
    "        self.yolo_images_train = os.path.join(self.yolo_dataset_dir, 'images', 'train')\n",
    "        self.yolo_images_val = os.path.join(self.yolo_dataset_dir, 'images', 'val')\n",
    "        self.yolo_labels_train = os.path.join(self.yolo_dataset_dir, 'labels', 'train')\n",
    "        self.yolo_labels_val = os.path.join(self.yolo_dataset_dir, 'labels', 'val')\n",
    "        self.yolo_weights_dir = os.path.join(self.working_dir, 'yolo_weights')\n",
    "\n",
    "\n",
    "        # 3d Encoder settings\n",
    "        self.strides = (2, 2, 2)\n",
    "        self.in_channels = 1\n",
    "        \n",
    "\n",
    "        # YOLO settings\n",
    "        self.img_size = 640\n",
    "        self.yolo_epochs = 100\n",
    "        self.yolo_pretrained_weights = \"yolov8n.pt\"\n",
    "        self.yolo_box_size = 30\n",
    "\n",
    "        # Depth Estimation settings\n",
    "        self.depth_epochs = 100\n",
    "        self.depth_size_profile = \n",
    "\n",
    "class GPUProfiler:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        elapsed = time.time() - self.start_time\n",
    "        # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n",
    "\n",
    "config = Config()\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "if device.startswith('cuda'):\n",
    "    # Set CUDA optimization flags\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True  # Allow TF32 on Ampere GPUs\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "    # Print GPU info\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "    print(f\"Using GPU: {gpu_name} with {gpu_mem:.2f} GB memory\")\n",
    "\n",
    "    # Get available GPU memory and set batch size accordingly\n",
    "    free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9\n",
    "    config.batch_size = max(8, min(32, int(free_mem * 4)))  # 4 images per GB as rough estimate\n",
    "    print(f\"Dynamic batch size set to {config.batch_size} based on {free_mem:.2f}GB free memory\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "    config.batch_size = 4  # Reduce batch size for CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77331833",
   "metadata": {},
   "source": [
    "# 1 Preprocess Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ea47f",
   "metadata": {},
   "source": [
    "## 1.1 3D-2D encoder\n",
    "\n",
    "(1) 強度正規化・クリッピング\n",
    "- HU値は与えられていないため強度の正規化は省略\n",
    "(2) 最小限のパディング\n",
    "- 3D Encoderのダウンサンプリング段数に合わせて、各空間軸を2のn乗に合わせる\n",
    "    - Downsampling stride: 32\n",
    "- バッチ処理はバッチ内最大サイズに揃える\n",
    "(3) Tensor化\n",
    "- torch.Tensorに変換する\n",
    "(4) Down-sampling\n",
    "- 各層で半分に3d-down-sampling\n",
    "(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec2f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib  # or pydicom, SimpleITK, etc.\n",
    "\n",
    "# DataLoader\n",
    "dataset = Patch3DDataset(image_paths, patch_size=(64,64,64), transforms=my_preproc)\n",
    "loader  = DataLoader(dataset, batch_size=2, num_workers=config.num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed8ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yolo\n",
    "\n",
    "class Patch3DDataset(Dataset):\n",
    "    def __init__(self, image_paths, patch_size=(64,64,64), transforms=None):\n",
    "        self.paths = image_paths\n",
    "        self.patch_size = patch_size\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1) ボリュームをメモリマップ or メインメモリへ読み込み\n",
    "        img = nib.load(self.paths[idx]).get_fdata(dtype=np.float32)\n",
    "        D, H, W = img.shape\n",
    "\n",
    "        # 2) ランダムに patch の開始位置をサンプリング\n",
    "        pd, ph, pw = self.patch_size\n",
    "        d0 = np.random.randint(0, max(D - pd + 1, 1))\n",
    "        h0 = np.random.randint(0, max(H - ph + 1, 1))\n",
    "        w0 = np.random.randint(0, max(W - pw + 1, 1))\n",
    "\n",
    "        # 3) スライスアウト\n",
    "        patch = img[d0:d0+pd, h0:h0+ph, w0:w0+pw]\n",
    "\n",
    "        # 4) 必要なら前処理／正規化\n",
    "        if self.transforms:\n",
    "            patch = self.transforms(patch)\n",
    "\n",
    "        # 5) Tensor へ変換\n",
    "        return torch.from_numpy(patch).unsqueeze(0)  # [1, D, H, W]\n",
    "\n",
    "class Dynamic3D2DEncoder(nn.Module):\n",
    "    def __init__(self, in_ch=1, base_ch=32, strides=(2,2,2)):\n",
    "        super().__init__()\n",
    "        # 3D Encoder：各層で半分にダウンサンプリング\n",
    "        layers = []\n",
    "        ch = in_ch\n",
    "        for _ in range(3):  # 4層ダウンサンプリング\n",
    "            layers += [\n",
    "                nn.Conv3d(ch, base_ch, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm3d(base_ch), nn.ReLU(inplace=True),\n",
    "                nn.MaxPool3d(strides)\n",
    "            ]\n",
    "            ch = base_ch\n",
    "            base_ch *= 2\n",
    "        self.encoder3d = nn.Sequential(*layers)\n",
    "        # 深度を 1 に縮約\n",
    "        self.depth_pool = nn.AdaptiveAvgPool3d((1, None, None))\n",
    "\n",
    "    def forward(self, x3d, yolo_size=(640,640)):\n",
    "        # x3d: [B,1,D_i,H_i,W_i]　※D_i,H_i,W_i は動的\n",
    "        feat3d = self.encoder3d(x3d)            # → [B, C, D', H', W']\n",
    "        feat3d = self.depth_pool(feat3d)        # → [B, C, 1, H', W']\n",
    "        feat2d = feat3d.squeeze(2)              # → [B, C, H', W']\n",
    "        # YOLO が想定する (H_y, W_y) に合わせてリサイズ\n",
    "        feat2d = F.interpolate(feat2d,\n",
    "                              size=yolo_size,\n",
    "                              mode='bilinear',\n",
    "                              align_corners=False)\n",
    "        return feat2d  # → [B, C, H_y, W_y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c386645",
   "metadata": {},
   "source": [
    "# 2. Detecting 2d position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da059f",
   "metadata": {},
   "source": [
    "Encoderに通して2次元に畳み込みを行った画像群にYOLOを適用する。\n",
    "1. YOLO形式のannotationを生成する\n",
    "- bboxは既存のものを流用する\n",
    "2. YOLOに入力\n",
    "3. Prediction\n",
    "- 推論を行う。出力されるのは$(x,y)$のみであるため、Z方向に対しては別のモデルを用いて予測を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f44daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStageDetector(nn.Module):\n",
    "    def __init__(self, num_classes, yolo_size=(640,640)):\n",
    "        super().__init__()\n",
    "        self.encoder = Dynamic3D2DEncoder(in_ch=1, base_ch=32)\n",
    "        # YOLO のバックボーン最初のチャネル数を合わせる\n",
    "        self.yolo = YOLOv5(backbone_in_ch=32, num_classes=num_classes)\n",
    "        self.yolo_size = yolo_size\n",
    "\n",
    "    def forward(self, x3d):\n",
    "        feat2d = self.encoder(x3d, yolo_size=self.yolo_size)\n",
    "        detections = self.yolo(feat2d)  # 通常の YOLO 推論\n",
    "        return detections\n",
    "    \n",
    "    def predict_on_samples(self, model):\n",
    "        val_dir = os.path.join(config.data_dir, 'val')\n",
    "        val_images = sorted(os.listdir(val_dir))\n",
    "        num_samples = min(num_samples, len(val_images))\n",
    "        samples = random.sample(val_images, num_samples)\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, img_file in enumerate(samples):\n",
    "            if i >= len(axes):\n",
    "                break\n",
    "\n",
    "            img_path = os.path.join(val_dir, img_file)\n",
    "            results = model.predict(img_path, conf=0.25)[0]\n",
    "            img = Image.open(img_path)\n",
    "            axes[i].imshow(np.array(img), cmap='gray')\n",
    "\n",
    "            try:\n",
    "                parts = img_file.split('_')\n",
    "                y_part = [p for p in parts if p.startswith('y')]\n",
    "                x_part = [p for p in parts if p.startswith('x')]\n",
    "                if y_part and x_part:\n",
    "                    y_gt = int(y_part[0][1:])\n",
    "                    x_gt = int(x_part[0][1:].split('.')[0])\n",
    "                    rect_gt = Rectangle((x_gt - config.yolo_box_size//2, y_gt - config.yolo_box_size//2),\n",
    "                                        config.yolo_box_size,\n",
    "                                        config.yolo_box_size,\n",
    "                                        linewidth=1, edgecolor='g',\n",
    "                                        facecolor='none')\n",
    "                    axes[i].add_patch(rect_gt)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "            if len(results.boxes) > 0:\n",
    "                boxes = results.boxes.xyxy.cpu().numpy()\n",
    "                confs = results.boxes.conf.cpu().numpy()\n",
    "                for box, conf in zip(boxes, confs):\n",
    "                    x1, y1, x2, y2 = box\n",
    "                    rect_pred = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1, edgecolor='r', facecolor='none')\n",
    "                    axes[i].add_patch(rect_pred)\n",
    "                    axes[i].text(x1, y1-5, f'{conf:.2f}', color='red')\n",
    "\n",
    "            axes[i].set_title(f\"Image: {img_file}\\nGT (green) vs Pred (red)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(config.working_dir, 'predictions.png'))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e34a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_yaml_paths(yaml_path):\n",
    "    \"\"\"\n",
    "    Fix the paths in the YAML file to match the actual Kaggle directories.\n",
    "\n",
    "    Args:\n",
    "        yaml_path (str): Path to the original dataset YAML file.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the fixed YAML file.\n",
    "    \"\"\"\n",
    "    print(f\"Fixing YAML paths in {yaml_path}\")\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        yaml_data = yaml.safe_load(f)\n",
    "\n",
    "    if 'path' in yaml_data:\n",
    "        yaml_data['path'] = yolo_dataset_dir #TODO: Change path\n",
    "\n",
    "    fixed_yaml_path = os.path.join(WORKING_DIR, \"fixed_dataset.yaml\")\n",
    "    with open(fixed_yaml_path, 'w') as f:\n",
    "        yaml.dump(yaml_data, f)\n",
    "\n",
    "    print(f\"Created fixed YAML at {fixed_yaml_path} with path: {yaml_data.get('path')}\")\n",
    "    return fixed_yaml_path\n",
    "\n",
    "def plot_dfl_loss_curve(run_dir):\n",
    "    \"\"\"\n",
    "    Plot the DFL loss curves for training and validation, marking the best model.\n",
    "\n",
    "    Args:\n",
    "        run_dir (str): Directory where the training results are stored.\n",
    "    \"\"\"\n",
    "    results_csv = os.path.join(run_dir, 'results.csv')\n",
    "    if not os.path.exists(results_csv):\n",
    "        print(f\"Results file not found at {results_csv}\")\n",
    "        return\n",
    "\n",
    "    results_df = pd.read_csv(results_csv)\n",
    "    train_dfl_col = [col for col in results_df.columns if 'train/dfl_loss' in col]\n",
    "    val_dfl_col = [col for col in results_df.columns if 'val/dfl_loss' in col]\n",
    "\n",
    "    if not train_dfl_col or not val_dfl_col:\n",
    "        print(\"DFL loss columns not found in results CSV\")\n",
    "        print(f\"Available columns: {results_df.columns.tolist()}\")\n",
    "        return\n",
    "\n",
    "    train_dfl_col = train_dfl_col[0]\n",
    "    val_dfl_col = val_dfl_col[0]\n",
    "\n",
    "    best_epoch = results_df[val_dfl_col].idxmin()\n",
    "    best_val_loss = results_df.loc[best_epoch, val_dfl_col]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results_df['epoch'], results_df[train_dfl_col], label='Train DFL Loss')\n",
    "    plt.plot(results_df['epoch'], results_df[val_dfl_col], label='Validation DFL Loss')\n",
    "    plt.axvline(x=results_df.loc[best_epoch, 'epoch'], color='r', linestyle='--',\n",
    "                label=f'Best Model (Epoch {int(results_df.loc[best_epoch, \"epoch\"])}, Val Loss: {best_val_loss:.4f})')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('DFL Loss')\n",
    "    plt.title('Training and Validation DFL Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plot_path = os.path.join(run_dir, 'dfl_loss_curve.png')\n",
    "    plt.savefig(plot_path)\n",
    "    plt.savefig(os.path.join(WORKING_DIR, 'dfl_loss_curve.png')) #TODO: save to working dir\n",
    "\n",
    "    print(f\"Loss curve saved to {plot_path}\")\n",
    "    plt.close()\n",
    "\n",
    "    return best_epoch, best_val_loss\n",
    "\n",
    "def train_yolo_model(yaml_path, pretrained_weights_path, epochs, batch_size, img_size):\n",
    "    \"\"\"\n",
    "    Train the YOLO model using the specified parameters.\n",
    "\n",
    "    Args:\n",
    "        yaml_path (str): Path to the dataset YAML file.\n",
    "        pretrained_weights (str): Path to the pretrained weights file.\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        img_size (int): Image size for training.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the trained model weights.\n",
    "    \"\"\"\n",
    "    print(f\"Loading pre-trained weights from {pretrained_weights_path}\")\n",
    "    model = YOLO(pretrained_weights_path)\n",
    "\n",
    "    results = model.train(\n",
    "        data=yaml_path,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        img_size=img_size,\n",
    "        device=device,\n",
    "        project=config.yolo_weights_dir,\n",
    "        name='motor_detector',\n",
    "        exist_ok=True,\n",
    "        patience=5,\n",
    "        save_period=5,\n",
    "        val=True,\n",
    "        save_best=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    run_dir = os.path.join(config.yolo_weights_dir, 'motor_detector')\n",
    "    best_epoch, best_val_loss = plot_dfl_loss_curve(run_dir)\n",
    "    if best_epoch is not None:\n",
    "        print(f\"Best epoch: {best_epoch}, Best validation DFL loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc3879",
   "metadata": {},
   "source": [
    "# 3 Regression Z position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625e81d4",
   "metadata": {},
   "source": [
    "YOLOで検出した$(x,y)$に基づき、適切なZ座標を1次元畳み込みしたものから求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthRegressor1D(nn.Module):\n",
    "    def __init__(self, in_channels=1, base_ch=16, D_max=800):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, base_ch, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(base_ch, base_ch*2, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(base_ch*2, 1)\n",
    "\n",
    "    def forward(self, depth_profile):\n",
    "        # depth_profile: [B, D_i] … 元ボリューム V[z] を y,x でサンプリングしたもの\n",
    "        f = self.net(depth_profile.unsqueeze(1))  # → [B, C, 1]\n",
    "        return self.fc(f.squeeze(-1))              # → [B,1]\n",
    "\n",
    "# Evaluate the results\n",
    "from sklearn.metrics import fbeta_score\n",
    "def distance_metric(self, \n",
    "    solution: pd.DataFrame,\n",
    "    submission: pd.DataFrame,\n",
    "    thresh_ratio: float,\n",
    "    min_radius: float,\n",
    "):\n",
    "    coordinate_cols = ['Motor axis 0', 'Motor axis 1', 'Motor axis 2']\n",
    "    label_tensor = solution[coordinate_cols].values.reshape(len(solution), -1, len(coordinate_cols))\n",
    "    predicted_tensor = submission[coordinate_cols].values.reshape(len(submission), -1, len(coordinate_cols))\n",
    "    # Find the minimum euclidean distances between the true and predicted points\n",
    "    solution['distance'] = np.linalg.norm(label_tensor - predicted_tensor, axis=2).min(axis=1)\n",
    "    # Convert thresholds from angstroms to voxels\n",
    "    solution['thresholds'] = solution['Voxel spacing'].apply(lambda x: (min_radius * thresh_ratio) / x)\n",
    "    solution['predictions'] = submission['Has motor'].values\n",
    "    solution.loc[(solution['distance'] > solution['thresholds']) & (solution['Has motor'] == 1) & (submission['Has motor'] == 1), 'predictions'] = 0\n",
    "    return solution['predictions'].values\n",
    "\n",
    "def score(self, solution:pd.DataFrame, submission:pd.DataFrame, min_radius:float=1000, beta:float=2) -> float:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    solution (pd.DataFrame): DataFrame containing ground truth motor positions.\n",
    "    submission (pd.DataFrame): DataFrame containing predicted motor positions.\n",
    "\n",
    "    Returns:\n",
    "    float: FBeta score.\n",
    "\n",
    "    Example\n",
    "    --------\n",
    "    >>> solution = pd.DataFrame({\n",
    "    ...     'tomo_id': [0, 1, 2, 3],\n",
    "    ...     'Motor axis 0': [-1, 250, 100, 200],\n",
    "    ...     'Motor axis 1': [-1, 250, 100, 200],\n",
    "    ...     'Motor axis 2': [-1, 250, 100, 200],\n",
    "    ...     'Voxel spacing': [10, 10, 10, 10],\n",
    "    ...     'Has motor': [0, 1, 1, 1]\n",
    "    ... })\n",
    "    >>> submission = pd.DataFrame({\n",
    "    ...     'tomo_id': [0, 1, 2, 3],\n",
    "    ...     'Motor axis 0': [100, 251, 600, -1],\n",
    "    ...     'Motor axis 1': [100, 251, 600, -1],\n",
    "    ...     'Motor axis 2': [100, 251, 600, -1]\n",
    "    ... })\n",
    "    >>> score(solution, submission, 1000, 2)\n",
    "    0.3571428571428571\n",
    "    \"\"\"\n",
    "\n",
    "    solution = solution.sort_values('tomo_id').reset_index(drop=True)\n",
    "    submission = submission.sort_values('tomo_id').reset_index(drop=True)\n",
    "\n",
    "    filename_equiv_array = solution['tomo_id'].eq(submission['tomo_id'], fill_value=0).values\n",
    "\n",
    "    if np.sum(filename_equiv_array) != len(solution['tomo_id']):\n",
    "        raise ValueError('Submitted tomo_id values do not match the sample_submission file')\n",
    "\n",
    "    submission['Has motor'] = 1\n",
    "    # If any columns are missing an axis, it's marked with no motor\n",
    "    select = (submission[['Motor axis 0', 'Motor axis 1', 'Motor axis 2']] == -1).any(axis='columns')\n",
    "    submission.loc[select, 'Has motor'] = 0\n",
    "\n",
    "    cols = ['Has motor', 'Motor axis 0', 'Motor axis 1', 'Motor axis 2']\n",
    "    assert all(col in submission.columns for col in cols)\n",
    "\n",
    "    # Calculate a label of 0 or 1 using the 'has motor', and 'motor axis' values\n",
    "    predictions = self.distance_metric(\n",
    "        solution,\n",
    "        submission,\n",
    "        thresh_ratio=1.0,\n",
    "        min_radius=min_radius,\n",
    "    )\n",
    "\n",
    "    return fbeta_score(solution['Has motor'].values, predictions, beta=beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24599ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Starting 3D-2D Encoder Training\")\n",
    "    print(\"Starting YOLOv8 Training\")\n",
    "    print(\"Starting Depth Estimation Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bfbdcb",
   "metadata": {},
   "source": [
    "Z方向の長さが異なる場合\n",
    "サンプルの深さ $ D_i $ が異なる問題への対策\n",
    "1. 補完リサイズ\n",
    "- 下の深度プロファイル( $ D_i $)を事前に決めた固定長$D_t$にF.interpolateでリサイズ\n",
    "- F.interpolate(profile.unsqueeze(1), size=D_t, mode='linear').squeeze(1)を用いて線型補完を行う\n",
    "2. Adaptive Pooling\n",
    "- nn.AdaptiveAvgPool1d(D_t)でどの長さの入力でも自動的に$D_t$長にマッピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352a63dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape: torch.Size([2, 16, 1, 10, 10])\n",
      "y2.shape: torch.Size([2, 16, 50, 100, 100])\n",
      "y3.shape: torch.Size([2, 16, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# バッチサイズ2, チャネル16, 深さ50, 高さ200, 幅300 のダミー入力\n",
    "x = torch.randn(2, 16, 50, 200, 300)\n",
    "\n",
    "# ① 出力を (1, 10, 10) に揃えたい場合\n",
    "pool = nn.AdaptiveAvgPool3d((1, 10, 10))\n",
    "y = pool(x)\n",
    "# → y.shape == (2, 16, 1, 10, 10)\n",
    "\n",
    "# ② 深さはそのまま, 高さ・幅だけ (100,100) にしたい場合\n",
    "pool_hw = nn.AdaptiveAvgPool3d((None, 100, 100))\n",
    "y2 = pool_hw(x)\n",
    "# → y2.shape == (2, 16, 50, 100, 100)\n",
    "\n",
    "# ③ グローバル平均プーリングとして使う場合\n",
    "global_pool = nn.AdaptiveAvgPool3d(1)  \n",
    "# 1 は (1,1,1) と同義\n",
    "y3 = global_pool(x)\n",
    "# → y3.shape == (2, 16, 1, 1, 1)\n",
    "\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"y2.shape:\", y2.shape)\n",
    "print(\"y3.shape:\", y3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141330a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
