# Abstruct

- 

# Idea
- 2d-3d transformationがやっぱり有効そう https://www.kaggle.com/competitions/byu-locating-bacterial-flagellar-motors-2025/discussion/573491 より
    - なんとなく察していたけど、それに対してのアプローチを思いつかなかった
    - で述べられているtransformer baseのモデルが結構いいかもしれない
    - Encoder-Decoderモデル
    - https://pmc.ncbi.nlm.nih.gov/articles/PMC6022756/pdf/nihms973047.pdf
    - https://www.kaggle.com/code/hengck23/example-2d-3d-encoder-for-detr-head
    - シンプルにdata augmentationとHyper prameter tuningだけで戦うことが一つ
- 点群処理も有効かも
    - どうにかして先端を点群にすることができれば、それを用いて処理が行えると予想
    - 問題はそれらに使うことのできるリソースが少ない・・・
    - Colab Proは大規模データを扱うことが難しい。今回のコンペは画像が多すぎることが問題。

## 実装しようと思うモデル
- 3D画像を2D画像に畳み込み
- 畳み込んだ画像をもとにYOLOで検出
   - (x,y)が出力される

※これの問題点は大規模なtomogramを全て扱わないといけない点。
自前のGPUがあるならそれは実現可能であるものの、そうではないため対策が必要

## ChatGPTさんとの対話結果

3D Conv Encoder に入れるテンソル形状を揃えるためには、「すべてのボリュームを１つの固定形状に落とし込む」か「モデル側で可変形状を吸収する」か、あるいはそのハイブリッドで考えるのが王道です。下記、代表的アプローチを３つご紹介します。

---

## 1. 全体を固定体積にリサンプリング／リサイズする

### メリット
- ネットワーク設計が最もシンプル（常に同じサイズのテンソルを扱う）
- バッチ処理が楽

### デメリット
- 大幅なダウンサンプリングでディテールが失われるリスク
- 元座標への逆変換（スケール係数の管理）が必要

### やり方
1. **ターゲット形状を決める**  
   例：深さ \(D_t=256\)、高さ \(H_t=512\)、幅 \(W_t=512\)  
2. **前処理パイプライン**  
   ```python
   import torchio as tio

   preprocess = tio.Compose([
       # (1) 強度クリッピング／正規化
       tio.Clamp(-1000, 400),
       tio.ZNormalization(),
       # (2) 空間リサンプリング
       tio.Resample((D_t, H_t, W_t), image_interpolation='linear'),
   ])
   ```
3. **モデル入力**  
   - 以降の Encoder–Decoder や YOLO フロントエンドは常に \((1,D_t,H_t,W_t)\)  
4. **出力座標の逆スケール**  
   ```text
   x_org = x_pred * (W_org / W_t)
   y_org = y_pred * (H_org / H_t)
   z_org = z_pred * (D_org / D_t)
   ```
   として、元のボリューム座標系に戻します。

---

## 2. パッチベース（Crop & Padding）＋ スライディングウィンドウ

### メリット
- GPU メモリに合わせて局所的に高解像度を維持できる
- 部分的な情報欠落をオーバーラップで補える

### デメリット
- 推論時に全パッチをまとめ直す実装コストが増す
- ３D→２D プロジェクションをパッチごとに行うと，最終的に複数の 2D 画像ができ，結合戦略が必要

### やり方
1. **訓練時**  
   - 各ボリュームから固定サイズパッチ \((D_p,H_p,W_p)\) をランダムに切り出し  
   - パッチが小さいときはパディング、大きいときはランダムクロップ  
2. **推論時**  
   - オーバーラップありでボリューム全体をスライディングウィンドウ  
   - 各パッチに対し 3D→2D→YOLO→Z回帰 を実行  
   - XY は元パッチ内座標 → 全体アライメント，Z はパッチ深度オフセットを加算  
   - 重複領域はスコアに応じて NMS or 平均化  

---

## 3. ネットワーク内で可変入力を吸収する

### メリット
- 前処理が「正規化＋最小限のパディング」で済む  
- 解像度や形状のばらつきをモデル側で柔軟に吸収  

### デメリット
- アーキテクチャ設計が少し複雑  
- YOLO 部分は通常固定入力想定なので追加実装が必要

### やり方
1. **3D Encoder**  
   ```python
   # 畳み込み＋ストライドPOOL で任意の (D_i,H_i,W_i) から特徴量を抽出
   features = Encoder3D(in_ch=1)(volume)  # → [B,C,D',H',W']
   ```
2. **Adaptive Depth Collapse**  
   ```python
   # 深度方向を learnable に 1 に縮約
   pooled = nn.AdaptiveAvgPool3d((1, None, None))(features)
   x2d = pooled.squeeze(2)              # → [B,C,H',W']
   ```
3. **2D Decoder（必要なら）＋ YOLO への Resizing**  
   ```python
   # YOLO の想定入力サイズ (H_yo, W_yo) に合わせて
   x2d_resized = F.interpolate(x2d,
                               size=(H_yo, W_yo),
                               mode='bilinear',
                               align_corners=False)
   detections = YOLO(x2d_resized)
   ```
4. **Z 回帰**  
   - 検出した \((x,y)\) を元の特徴マップ座標系にマッピング  
   - 元の volume から深度プロファイルを取り出して 1D‐CNN／MLP で回帰  
   - （もしくは深度方向も AdaptivePool → 1チャネルに落としたものを併用して一気に予測）

---

## おすすめフロー

1. **まずは１．全体リサイズ方式** でプロトタイプを作る  
   - 実装が最速で、YOLO への入力マッピングもクリア  
    全体リサイズの場合
    1024 × 1440 × 800 のフルボリュームをそのまま 3D Conv に流すと…
    要素数：1 179 648 000 ボクセル
    float32 メモリ：1.18 × 10^9 × 4 bytes ≃ 4.7 GiB（入力テンソルだけで！）
    中間特徴マップ：Conv 層を重ねればチャネル数が増えるほどさらに数倍～数十倍
    バックプロパゲーション：アクティベーションの保存や勾配でさらにおよそ入力＋出力の 2 倍
    ――と考えると、GPU メモリが**32GiBでも足りない**ことがほとんど
    →ダウンサンプリングが必要になる
2. **次に ３．AdaptivePool＋動的リサイズ方式** を試し、解像度／サイズに対する頑健性をチェック  
3. **最後にパッチ方式** で大容量ボリュームを高精細に処理する段階へ

これらを段階的に実装・評価し、検出精度・速度・メモリ消費のバランスを見ながら最適化していくのが良いでしょう。
